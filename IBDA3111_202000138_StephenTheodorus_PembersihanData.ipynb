{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an exercise to apply the concepts of data cleansing and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable as pt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityList = []\n",
    "precisionList = []\n",
    "negativePredValuesList = []\n",
    "specificityList = []\n",
    "accuracyList = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model MLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model without any data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('./dataset/oil-spill.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2558</th>\n",
       "      <th>1506.09</th>\n",
       "      <th>456.63</th>\n",
       "      <th>90</th>\n",
       "      <th>6395000</th>\n",
       "      <th>40.88</th>\n",
       "      <th>7.89</th>\n",
       "      <th>29780</th>\n",
       "      <th>0.19</th>\n",
       "      <th>214.7</th>\n",
       "      <th>...</th>\n",
       "      <th>69</th>\n",
       "      <th>2850</th>\n",
       "      <th>1000</th>\n",
       "      <th>763.16</th>\n",
       "      <th>135.46</th>\n",
       "      <th>3.73</th>\n",
       "      <th>0.3</th>\n",
       "      <th>33243.19</th>\n",
       "      <th>65.74</th>\n",
       "      <th>7.95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>901.7</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>86.1</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500.0</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>166.5</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>232.8</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1438.13</td>\n",
       "      <td>544.91</td>\n",
       "      <td>82</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>44.67</td>\n",
       "      <td>6.92</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>608.28</td>\n",
       "      <td>200.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>52.22</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0</td>\n",
       "      <td>30967.25</td>\n",
       "      <td>65.77</td>\n",
       "      <td>7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200.0</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>65.85</td>\n",
       "      <td>6.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>107.2</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>65.70</td>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400.0</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>133.9</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>97.5</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>65.97</td>\n",
       "      <td>6.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>107.2</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>65.65</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      2558  1506.09  456.63   90     6395000  40.88   7.89    29780  0.19  \\\n",
       "0    22325    79.11  841.03  180  55812500.0  51.11   1.21  61900.0  0.02   \n",
       "1      115  1449.85  608.43   88    287500.0  40.42   7.34   3340.0  0.18   \n",
       "2     1201  1562.53  295.65   66   3002500.0  42.40   7.97  18030.0  0.19   \n",
       "3      312   950.27  440.86   37    780000.0  41.43   7.03   3350.0  0.17   \n",
       "4       54  1438.13  544.91   82    135000.0  44.67   6.92   1570.0  0.15   \n",
       "..     ...      ...     ...  ...         ...    ...    ...      ...   ...   \n",
       "931     12    92.42  364.42  135     97200.0  59.42  10.34    884.0  0.17   \n",
       "932     11    98.82  248.64  159     89100.0  59.64  10.18    831.0  0.17   \n",
       "933     14    25.14  428.86   24    113400.0  60.14  17.94    847.0  0.30   \n",
       "934     10    96.00  451.30   68     81000.0  59.90  15.01    831.0  0.25   \n",
       "935     11     7.73  235.73  135     89100.0  61.82  12.24    831.0  0.20   \n",
       "\n",
       "     214.7  ...  69     2850      1000   763.16   135.46   3.73  0.3  \\\n",
       "0    901.7  ...  69  5750.00  11500.00  9593.48  1648.80   0.60    0   \n",
       "1     86.1  ...  69  1400.00    250.00   150.00    45.13   9.33    1   \n",
       "2    166.5  ...  69  6041.52    761.58   453.21   144.97  13.33    1   \n",
       "3    232.8  ...  69  1320.04    710.63   512.54   109.16   2.58    0   \n",
       "4     86.0  ...  69   608.28    200.00   150.00    52.22   4.06    0   \n",
       "..     ...  ...  ..      ...       ...      ...      ...    ...  ...   \n",
       "931  110.0  ...  50   381.84    254.56    84.85   146.97   4.50    0   \n",
       "932  107.2  ...  50   284.60    180.00   150.00    51.96   1.90    0   \n",
       "933  133.9  ...  50   402.49    180.00   180.00     0.00   2.24    0   \n",
       "934   97.5  ...  50   402.49    180.00    90.00    73.48   4.47    0   \n",
       "935  107.2  ...  50   254.56    254.56   127.28   180.00   2.00    0   \n",
       "\n",
       "     33243.19  65.74  7.95  \n",
       "0    51572.04  65.73  6.26  \n",
       "1    31692.84  65.81  7.84  \n",
       "2    37696.21  65.67  8.07  \n",
       "3    29038.17  65.66  7.35  \n",
       "4    30967.25  65.77  7.85  \n",
       "..        ...    ...   ...  \n",
       "931   2593.50  65.85  6.39  \n",
       "932   4361.25  65.70  6.53  \n",
       "933   2153.05  65.91  6.12  \n",
       "934   2421.43  65.97  6.32  \n",
       "935   3782.68  65.65  6.26  \n",
       "\n",
       "[936 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "931    0\n",
       "932    0\n",
       "933    0\n",
       "934    0\n",
       "935    0\n",
       "Name: 1.1, Length: 936, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X1 = data1.iloc[:,1:-1]\n",
    "y1 = data1.iloc[:,-1]\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.3, random_state=42)  \n",
    "display(X1)\n",
    "display(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.54080077\n",
      "Iteration 2, loss = 1.54080048\n",
      "Iteration 3, loss = 1.54080022\n",
      "Iteration 4, loss = 1.54080000\n",
      "Iteration 5, loss = 1.54079983\n",
      "Iteration 6, loss = 0.97656443\n",
      "Iteration 7, loss = 0.84092440\n",
      "Iteration 8, loss = 0.71861154\n",
      "Iteration 9, loss = 1.08627012\n",
      "Iteration 10, loss = 0.78013285\n",
      "Iteration 11, loss = 0.75847936\n",
      "Iteration 12, loss = 0.73573582\n",
      "Iteration 13, loss = 0.71307137\n",
      "Iteration 14, loss = 0.69074568\n",
      "Iteration 15, loss = 0.66947088\n",
      "Iteration 16, loss = 0.64906021\n",
      "Iteration 17, loss = 1.03737547\n",
      "Iteration 18, loss = 0.61253711\n",
      "Iteration 19, loss = 0.59560789\n",
      "Iteration 20, loss = 0.57930979\n",
      "Iteration 21, loss = 0.56342967\n",
      "Iteration 22, loss = 0.54813157\n",
      "Iteration 23, loss = 0.53350770\n",
      "Iteration 24, loss = 0.51975364\n",
      "Iteration 25, loss = 0.50624877\n",
      "Iteration 26, loss = 0.49367570\n",
      "Iteration 27, loss = 0.48136459\n",
      "Iteration 28, loss = 0.46979708\n",
      "Iteration 29, loss = 0.45866127\n",
      "Iteration 30, loss = 0.44808516\n",
      "Iteration 31, loss = 0.43785149\n",
      "Iteration 32, loss = 0.42829618\n",
      "Iteration 33, loss = 0.41916457\n",
      "Iteration 34, loss = 0.41023518\n",
      "Iteration 35, loss = 0.40182676\n",
      "Iteration 36, loss = 0.39367822\n",
      "Iteration 37, loss = 0.38604613\n",
      "Iteration 38, loss = 0.37861055\n",
      "Iteration 39, loss = 0.37152243\n",
      "Iteration 40, loss = 0.36473120\n",
      "Iteration 41, loss = 0.35822916\n",
      "Iteration 42, loss = 0.35205672\n",
      "Iteration 43, loss = 0.34588886\n",
      "Iteration 44, loss = 0.34016858\n",
      "Iteration 45, loss = 0.33467582\n",
      "Iteration 46, loss = 0.32927843\n",
      "Iteration 47, loss = 0.32414019\n",
      "Iteration 48, loss = 0.31939883\n",
      "Iteration 49, loss = 0.31473211\n",
      "Iteration 50, loss = 0.31019325\n",
      "Iteration 51, loss = 0.30596890\n",
      "Iteration 52, loss = 0.30179189\n",
      "Iteration 53, loss = 0.29768915\n",
      "Iteration 54, loss = 0.29380628\n",
      "Iteration 55, loss = 0.29000860\n",
      "Iteration 56, loss = 0.28634169\n",
      "Iteration 57, loss = 0.28289709\n",
      "Iteration 58, loss = 0.27949483\n",
      "Iteration 59, loss = 0.27622643\n",
      "Iteration 60, loss = 0.27313909\n",
      "Iteration 61, loss = 0.27008508\n",
      "Iteration 62, loss = 0.26717457\n",
      "Iteration 63, loss = 0.26434419\n",
      "Iteration 64, loss = 0.26151282\n",
      "Iteration 65, loss = 0.25894520\n",
      "Iteration 66, loss = 0.25639098\n",
      "Iteration 67, loss = 0.25405902\n",
      "Iteration 68, loss = 0.25168590\n",
      "Iteration 69, loss = 0.24953926\n",
      "Iteration 70, loss = 0.24739106\n",
      "Iteration 71, loss = 0.24532237\n",
      "Iteration 72, loss = 0.24327828\n",
      "Iteration 73, loss = 0.24133218\n",
      "Iteration 74, loss = 0.23937557\n",
      "Iteration 75, loss = 0.23764008\n",
      "Iteration 76, loss = 0.23575552\n",
      "Iteration 77, loss = 0.23402287\n",
      "Iteration 78, loss = 0.23231500\n",
      "Iteration 79, loss = 0.23066736\n",
      "Iteration 80, loss = 0.22902374\n",
      "Iteration 81, loss = 0.22746064\n",
      "Iteration 82, loss = 0.22597936\n",
      "Iteration 83, loss = 0.22447542\n",
      "Iteration 84, loss = 0.22309165\n",
      "Iteration 85, loss = 0.22177177\n",
      "Iteration 86, loss = 0.22040051\n",
      "Iteration 87, loss = 0.21919152\n",
      "Iteration 88, loss = 0.21799038\n",
      "Iteration 89, loss = 0.21682109\n",
      "Iteration 90, loss = 0.21567551\n",
      "Iteration 91, loss = 0.21459338\n",
      "Iteration 92, loss = 0.21356834\n",
      "Iteration 93, loss = 0.21256321\n",
      "Iteration 94, loss = 0.21158460\n",
      "Iteration 95, loss = 0.21059338\n",
      "Iteration 96, loss = 0.20964687\n",
      "Iteration 97, loss = 0.20874695\n",
      "Iteration 98, loss = 0.20786767\n",
      "Iteration 99, loss = 0.20700073\n",
      "Iteration 100, loss = 0.20616903\n",
      "Iteration 101, loss = 0.20539864\n",
      "Iteration 102, loss = 0.20468956\n",
      "Iteration 103, loss = 0.20391715\n",
      "Iteration 104, loss = 0.20323241\n",
      "Iteration 105, loss = 0.20251629\n",
      "Iteration 106, loss = 0.20184114\n",
      "Iteration 107, loss = 0.20118766\n",
      "Iteration 108, loss = 0.20052948\n",
      "Iteration 109, loss = 0.19994311\n",
      "Iteration 110, loss = 0.19927176\n",
      "Iteration 111, loss = 0.24222436\n",
      "Iteration 112, loss = 0.19808817\n",
      "Iteration 113, loss = 0.19759125\n",
      "Iteration 114, loss = 0.19701299\n",
      "Iteration 115, loss = 0.19648459\n",
      "Iteration 116, loss = 0.19596329\n",
      "Iteration 117, loss = 0.19543125\n",
      "Iteration 118, loss = 0.19496661\n",
      "Iteration 119, loss = 0.19443423\n",
      "Iteration 120, loss = 0.19396827\n",
      "Iteration 121, loss = 0.19348240\n",
      "Iteration 122, loss = 0.19304892\n",
      "Iteration 123, loss = 0.19259331\n",
      "Iteration 124, loss = 0.19219448\n",
      "Iteration 125, loss = 0.19178843\n",
      "Iteration 126, loss = 0.19133576\n",
      "Iteration 127, loss = 0.19092876\n",
      "Iteration 128, loss = 0.19051108\n",
      "Iteration 129, loss = 0.19018062\n",
      "Iteration 130, loss = 0.18981245\n",
      "Iteration 131, loss = 0.18944768\n",
      "Iteration 132, loss = 0.18915805\n",
      "Iteration 133, loss = 0.18881997\n",
      "Iteration 134, loss = 0.18850099\n",
      "Iteration 135, loss = 0.18819781\n",
      "Iteration 136, loss = 0.18790398\n",
      "Iteration 137, loss = 0.18757964\n",
      "Iteration 138, loss = 0.18732204\n",
      "Iteration 139, loss = 0.18700433\n",
      "Iteration 140, loss = 0.18672474\n",
      "Iteration 141, loss = 0.18645603\n",
      "Iteration 142, loss = 0.18617586\n",
      "Iteration 143, loss = 0.18595766\n",
      "Iteration 144, loss = 0.18567520\n",
      "Iteration 145, loss = 0.18544419\n",
      "Iteration 146, loss = 0.18520527\n",
      "Iteration 147, loss = 0.18496565\n",
      "Iteration 148, loss = 0.18471732\n",
      "Iteration 149, loss = 0.18449688\n",
      "Iteration 150, loss = 0.18428241\n",
      "Iteration 151, loss = 0.18406887\n",
      "Iteration 152, loss = 0.18389874\n",
      "Iteration 153, loss = 0.18370679\n",
      "Iteration 154, loss = 0.18351347\n",
      "Iteration 155, loss = 0.18334702\n",
      "Iteration 156, loss = 0.18318871\n",
      "Iteration 157, loss = 0.18299597\n",
      "Iteration 158, loss = 0.18282459\n",
      "Iteration 159, loss = 0.18269006\n",
      "Iteration 160, loss = 0.18253451\n",
      "Iteration 161, loss = 0.18235543\n",
      "Iteration 162, loss = 0.18219246\n",
      "Iteration 163, loss = 0.18204611\n",
      "Iteration 164, loss = 0.18188016\n",
      "Iteration 165, loss = 0.18173678\n",
      "Iteration 166, loss = 0.18158710\n",
      "Iteration 167, loss = 0.18147952\n",
      "Iteration 168, loss = 0.18135210\n",
      "Iteration 169, loss = 0.18123981\n",
      "Iteration 170, loss = 0.18112391\n",
      "Iteration 171, loss = 0.18102316\n",
      "Iteration 172, loss = 0.18089868\n",
      "Iteration 173, loss = 0.18080375\n",
      "Iteration 174, loss = 0.18068869\n",
      "Iteration 175, loss = 0.18058620\n",
      "Iteration 176, loss = 0.18049557\n",
      "Iteration 177, loss = 0.18034474\n",
      "Iteration 178, loss = 0.18026562\n",
      "Iteration 179, loss = 0.18016239\n",
      "Iteration 180, loss = 0.18007647\n",
      "Iteration 181, loss = 0.17996991\n",
      "Iteration 182, loss = 0.17988576\n",
      "Iteration 183, loss = 0.17982777\n",
      "Iteration 184, loss = 0.17975196\n",
      "Iteration 185, loss = 0.17966730\n",
      "Iteration 186, loss = 0.17960628\n",
      "Iteration 187, loss = 0.17951519\n",
      "Iteration 188, loss = 0.17946167\n",
      "Iteration 189, loss = 0.17938223\n",
      "Iteration 190, loss = 0.17931145\n",
      "Iteration 191, loss = 0.17923734\n",
      "Iteration 192, loss = 0.17917114\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(3, 2), learning_rate_init=0.01,\n",
       "              random_state=5, verbose=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = MLPClassifier(hidden_layer_sizes=(3,2),\n",
    "                    random_state=5,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.01)\n",
    "clf1.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = clf1.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 269                   0\n",
       "Actual Positive                  12                   0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the confusion matrix\n",
    "cm1 = metrics.confusion_matrix(y_test1, y_pred1)\n",
    "# Assigning columns names\n",
    "cm_df1 = pd.DataFrame(cm1, \n",
    "            columns = ['Predicted Negative', 'Predicted Positive'],\n",
    "            index = ['Actual Negative', 'Actual Positive'])\n",
    "# Showing the confusion matrix\n",
    "cm_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric (conf_matrix):\n",
    "    TP = conf_matrix[1][1]\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "    sensitivity = ((TP / (TP+FN)))\n",
    "    precision = ((TP/(TP+FP)))\n",
    "    negativePredValues = (TN/(TN+FN))\n",
    "    specificity = (TN / (TN+FP))\n",
    "    accuracy = ((TP+TN)/(TP+TN+FP+FN))\n",
    "    print('True Positives:', TP)\n",
    "    print('True Negatives:', TN)\n",
    "    print('False Positives:', FP)\n",
    "    print('False Negatives:', FN)\n",
    "    return sensitivity,precision,negativePredValues,specificity,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 0\n",
      "True Negatives: 269\n",
      "False Positives: 0\n",
      "False Negatives: 12\n",
      "Sensitivity: 0.0\n",
      "Precision = nan\n",
      "Negative Pred Value = 0.9572953736654805\n",
      "Specificity = 1.0\n",
      "Accuracy = 0.9572953736654805\n"
     ]
    }
   ],
   "source": [
    "sensitivity1,precision1,negativePredValues1,specificity1,accuracy1 = metric(cm1)\n",
    "sensitivityList.append(sensitivity1)\n",
    "precisionList.append(precision1)\n",
    "negativePredValuesList.append(negativePredValues1)\n",
    "specificityList.append(specificity1)\n",
    "accuracyList.append(accuracy1)\n",
    "print(f'Sensitivity: {sensitivity1}')\n",
    "print(f'Precision = {precision1}')\n",
    "print(f'Negative Pred Value = {negativePredValues1}')\n",
    "print(f'Specificity = {specificity1}')\n",
    "print(f'Accuracy = {accuracy1}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with single value data filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000.0</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500.0</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200.0</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>65.85</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>201</td>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>65.70</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400.0</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>203</td>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>65.97</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>204</td>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>65.65</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1        2       3    4           5      6      7        8   \\\n",
       "0      1   2558  1506.09  456.63   90   6395000.0  40.88   7.89  29780.0   \n",
       "1      2  22325    79.11  841.03  180  55812500.0  51.11   1.21  61900.0   \n",
       "2      3    115  1449.85  608.43   88    287500.0  40.42   7.34   3340.0   \n",
       "3      4   1201  1562.53  295.65   66   3002500.0  42.40   7.97  18030.0   \n",
       "4      5    312   950.27  440.86   37    780000.0  41.43   7.03   3350.0   \n",
       "..   ...    ...      ...     ...  ...         ...    ...    ...      ...   \n",
       "932  200     12    92.42  364.42  135     97200.0  59.42  10.34    884.0   \n",
       "933  201     11    98.82  248.64  159     89100.0  59.64  10.18    831.0   \n",
       "934  202     14    25.14  428.86   24    113400.0  60.14  17.94    847.0   \n",
       "935  203     10    96.00  451.30   68     81000.0  59.90  15.01    831.0   \n",
       "936  204     11     7.73  235.73  135     89100.0  61.82  12.24    831.0   \n",
       "\n",
       "       9   ...       40        41       42       43     44  45        46  \\\n",
       "0    0.19  ...  2850.00   1000.00   763.16   135.46   3.73   0  33243.19   \n",
       "1    0.02  ...  5750.00  11500.00  9593.48  1648.80   0.60   0  51572.04   \n",
       "2    0.18  ...  1400.00    250.00   150.00    45.13   9.33   1  31692.84   \n",
       "3    0.19  ...  6041.52    761.58   453.21   144.97  13.33   1  37696.21   \n",
       "4    0.17  ...  1320.04    710.63   512.54   109.16   2.58   0  29038.17   \n",
       "..    ...  ...      ...       ...      ...      ...    ...  ..       ...   \n",
       "932  0.17  ...   381.84    254.56    84.85   146.97   4.50   0   2593.50   \n",
       "933  0.17  ...   284.60    180.00   150.00    51.96   1.90   0   4361.25   \n",
       "934  0.30  ...   402.49    180.00   180.00     0.00   2.24   0   2153.05   \n",
       "935  0.25  ...   402.49    180.00    90.00    73.48   4.47   0   2421.43   \n",
       "936  0.20  ...   254.56    254.56   127.28   180.00   2.00   0   3782.68   \n",
       "\n",
       "        47    48  49  \n",
       "0    65.74  7.95   1  \n",
       "1    65.73  6.26   0  \n",
       "2    65.81  7.84   1  \n",
       "3    65.67  8.07   1  \n",
       "4    65.66  7.35   0  \n",
       "..     ...   ...  ..  \n",
       "932  65.85  6.39   0  \n",
       "933  65.70  6.53   0  \n",
       "934  65.91  6.12   0  \n",
       "935  65.97  6.32   0  \n",
       "936  65.65  6.26   0  \n",
       "\n",
       "[937 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data2 = pd.read_csv('./dataset/oil-spill.csv',header=None)\n",
    "display(data2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching and delete Single Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom yang akan didelete adalah: [22]\n"
     ]
    }
   ],
   "source": [
    "counts = data2.nunique()\n",
    "toDel2 = [i for i,v in enumerate(counts) if v == 1]\n",
    "print(f'Kolom yang akan didelete adalah: {toDel2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    937\n",
       "Name: 22, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[22].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Akhir = (937, 49)\n"
     ]
    }
   ],
   "source": [
    "data2.drop(toDel2, axis=1, inplace=True)\n",
    "print(f'Shape Akhir = {data2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = data2.iloc[:,1:-1]\n",
    "y2 = data2.iloc[:,-1]\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000.0</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>214.7</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>901.7</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>86.1</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500.0</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>166.5</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>232.8</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200.0</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>65.85</td>\n",
       "      <td>6.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>107.2</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>65.70</td>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400.0</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>133.9</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>97.5</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>65.97</td>\n",
       "      <td>6.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>107.2</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>65.65</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1        2       3    4           5      6      7        8     9   \\\n",
       "0     2558  1506.09  456.63   90   6395000.0  40.88   7.89  29780.0  0.19   \n",
       "1    22325    79.11  841.03  180  55812500.0  51.11   1.21  61900.0  0.02   \n",
       "2      115  1449.85  608.43   88    287500.0  40.42   7.34   3340.0  0.18   \n",
       "3     1201  1562.53  295.65   66   3002500.0  42.40   7.97  18030.0  0.19   \n",
       "4      312   950.27  440.86   37    780000.0  41.43   7.03   3350.0  0.17   \n",
       "..     ...      ...     ...  ...         ...    ...    ...      ...   ...   \n",
       "932     12    92.42  364.42  135     97200.0  59.42  10.34    884.0  0.17   \n",
       "933     11    98.82  248.64  159     89100.0  59.64  10.18    831.0  0.17   \n",
       "934     14    25.14  428.86   24    113400.0  60.14  17.94    847.0  0.30   \n",
       "935     10    96.00  451.30   68     81000.0  59.90  15.01    831.0  0.25   \n",
       "936     11     7.73  235.73  135     89100.0  61.82  12.24    831.0  0.20   \n",
       "\n",
       "        10  ...  39       40        41       42       43     44  45        46  \\\n",
       "0    214.7  ...  69  2850.00   1000.00   763.16   135.46   3.73   0  33243.19   \n",
       "1    901.7  ...  69  5750.00  11500.00  9593.48  1648.80   0.60   0  51572.04   \n",
       "2     86.1  ...  69  1400.00    250.00   150.00    45.13   9.33   1  31692.84   \n",
       "3    166.5  ...  69  6041.52    761.58   453.21   144.97  13.33   1  37696.21   \n",
       "4    232.8  ...  69  1320.04    710.63   512.54   109.16   2.58   0  29038.17   \n",
       "..     ...  ...  ..      ...       ...      ...      ...    ...  ..       ...   \n",
       "932  110.0  ...  50   381.84    254.56    84.85   146.97   4.50   0   2593.50   \n",
       "933  107.2  ...  50   284.60    180.00   150.00    51.96   1.90   0   4361.25   \n",
       "934  133.9  ...  50   402.49    180.00   180.00     0.00   2.24   0   2153.05   \n",
       "935   97.5  ...  50   402.49    180.00    90.00    73.48   4.47   0   2421.43   \n",
       "936  107.2  ...  50   254.56    254.56   127.28   180.00   2.00   0   3782.68   \n",
       "\n",
       "        47    48  \n",
       "0    65.74  7.95  \n",
       "1    65.73  6.26  \n",
       "2    65.81  7.84  \n",
       "3    65.67  8.07  \n",
       "4    65.66  7.35  \n",
       "..     ...   ...  \n",
       "932  65.85  6.39  \n",
       "933  65.70  6.53  \n",
       "934  65.91  6.12  \n",
       "935  65.97  6.32  \n",
       "936  65.65  6.26  \n",
       "\n",
       "[937 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "932    0\n",
       "933    0\n",
       "934    0\n",
       "935    0\n",
       "936    0\n",
       "Name: 49, Length: 937, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X2)\n",
    "display(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 34.39280185\n",
      "Iteration 2, loss = 30.85146030\n",
      "Iteration 3, loss = 1.65085731\n",
      "Iteration 4, loss = 1.65085736\n",
      "Iteration 5, loss = 1.65085737\n",
      "Iteration 6, loss = 1.65085734\n",
      "Iteration 7, loss = 1.65085729\n",
      "Iteration 8, loss = 1.65085723\n",
      "Iteration 9, loss = 1.65085718\n",
      "Iteration 10, loss = 1.65085712\n",
      "Iteration 11, loss = 1.65085707\n",
      "Iteration 12, loss = 1.65085702\n",
      "Iteration 13, loss = 1.65085698\n",
      "Iteration 14, loss = 1.65085694\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(3, 2), learning_rate_init=0.01,\n",
       "              random_state=5, verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = MLPClassifier(hidden_layer_sizes=(3,2),\n",
    "                    random_state=5,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.01)\n",
    "clf2.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = clf2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 271                   0\n",
       "Actual Positive                  11                   0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the confusion matrix\n",
    "cm2 = metrics.confusion_matrix(y_test2, y_pred2)\n",
    "# Assigning columns names\n",
    "cm_df2 = pd.DataFrame(cm2, \n",
    "            columns = ['Predicted Negative', 'Predicted Positive'],\n",
    "            index = ['Actual Negative', 'Actual Positive'])\n",
    "# Showing the confusion matrix\n",
    "cm_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 0\n",
      "True Negatives: 271\n",
      "False Positives: 0\n",
      "False Negatives: 11\n",
      "Sensitivity: 0.0\n",
      "Precision = nan\n",
      "Negative Pred Value = 0.9609929078014184\n",
      "Specificity = 1.0\n",
      "Accuracy = 0.9609929078014184\n"
     ]
    }
   ],
   "source": [
    "sensitivity2,precision2,negativePredValues2,specificity2,accuracy2 = metric(cm2)\n",
    "sensitivityList.append(sensitivity2)\n",
    "precisionList.append(precision2)\n",
    "negativePredValuesList.append(negativePredValues2)\n",
    "specificityList.append(specificity2)\n",
    "accuracyList.append(accuracy2)\n",
    "print(f'Sensitivity: {sensitivity2}')\n",
    "print(f'Precision = {precision2}')\n",
    "print(f'Negative Pred Value = {negativePredValues2}')\n",
    "print(f'Specificity = {specificity2}')\n",
    "print(f'Accuracy = {accuracy2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with few values filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000.0</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500.0</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200.0</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>65.85</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>201</td>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>65.70</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400.0</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>203</td>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>65.97</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>204</td>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>65.65</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1        2       3    4           5      6      7        8   \\\n",
       "0      1   2558  1506.09  456.63   90   6395000.0  40.88   7.89  29780.0   \n",
       "1      2  22325    79.11  841.03  180  55812500.0  51.11   1.21  61900.0   \n",
       "2      3    115  1449.85  608.43   88    287500.0  40.42   7.34   3340.0   \n",
       "3      4   1201  1562.53  295.65   66   3002500.0  42.40   7.97  18030.0   \n",
       "4      5    312   950.27  440.86   37    780000.0  41.43   7.03   3350.0   \n",
       "..   ...    ...      ...     ...  ...         ...    ...    ...      ...   \n",
       "932  200     12    92.42  364.42  135     97200.0  59.42  10.34    884.0   \n",
       "933  201     11    98.82  248.64  159     89100.0  59.64  10.18    831.0   \n",
       "934  202     14    25.14  428.86   24    113400.0  60.14  17.94    847.0   \n",
       "935  203     10    96.00  451.30   68     81000.0  59.90  15.01    831.0   \n",
       "936  204     11     7.73  235.73  135     89100.0  61.82  12.24    831.0   \n",
       "\n",
       "       9   ...       40        41       42       43     44  45        46  \\\n",
       "0    0.19  ...  2850.00   1000.00   763.16   135.46   3.73   0  33243.19   \n",
       "1    0.02  ...  5750.00  11500.00  9593.48  1648.80   0.60   0  51572.04   \n",
       "2    0.18  ...  1400.00    250.00   150.00    45.13   9.33   1  31692.84   \n",
       "3    0.19  ...  6041.52    761.58   453.21   144.97  13.33   1  37696.21   \n",
       "4    0.17  ...  1320.04    710.63   512.54   109.16   2.58   0  29038.17   \n",
       "..    ...  ...      ...       ...      ...      ...    ...  ..       ...   \n",
       "932  0.17  ...   381.84    254.56    84.85   146.97   4.50   0   2593.50   \n",
       "933  0.17  ...   284.60    180.00   150.00    51.96   1.90   0   4361.25   \n",
       "934  0.30  ...   402.49    180.00   180.00     0.00   2.24   0   2153.05   \n",
       "935  0.25  ...   402.49    180.00    90.00    73.48   4.47   0   2421.43   \n",
       "936  0.20  ...   254.56    254.56   127.28   180.00   2.00   0   3782.68   \n",
       "\n",
       "        47    48  49  \n",
       "0    65.74  7.95   1  \n",
       "1    65.73  6.26   0  \n",
       "2    65.81  7.84   1  \n",
       "3    65.67  8.07   1  \n",
       "4    65.66  7.35   0  \n",
       "..     ...   ...  ..  \n",
       "932  65.85  6.39   0  \n",
       "933  65.70  6.53   0  \n",
       "934  65.91  6.12   0  \n",
       "935  65.97  6.32   0  \n",
       "936  65.65  6.26   0  \n",
       "\n",
       "[937 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data3 = pd.read_csv('./dataset/oil-spill.csv',header=None)\n",
    "display(data3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching and delete  few values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Awal = (937, 50)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape Awal = {data3.shape}')\n",
    "# get number of unique values for each column\n",
    "counts3 = data3.nunique()\n",
    "# record columns to delete\n",
    "to_del3 = [i for i,v in enumerate(counts3) if (float(v)/data3.shape[0]*100) < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom yang akan di delete = [21, 22, 24, 25, 26, 32, 36, 38, 39, 45]\n"
     ]
    }
   ],
   "source": [
    "if data3.shape[1]-1 in to_del3:\n",
    "    to_del3.remove(data3.shape[1]-1)\n",
    "print(f'Kolom yang akan di delete = {to_del3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Akhir = (937, 40)\n"
     ]
    }
   ],
   "source": [
    "data3.drop(to_del3, axis=1, inplace=True)\n",
    "print(f'Shape Akhir = {data3.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = data3.iloc[:,1:-1]\n",
    "y3 = data3.iloc[:,-1]\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>37</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000.0</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>214.7</td>\n",
       "      <td>...</td>\n",
       "      <td>16110</td>\n",
       "      <td>138.68</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>901.7</td>\n",
       "      <td>...</td>\n",
       "      <td>40140</td>\n",
       "      <td>68.65</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>86.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1530</td>\n",
       "      <td>38.80</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500.0</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>166.5</td>\n",
       "      <td>...</td>\n",
       "      <td>10080</td>\n",
       "      <td>108.27</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>232.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2340</td>\n",
       "      <td>14.39</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200.0</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>540</td>\n",
       "      <td>8.04</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>65.85</td>\n",
       "      <td>6.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>107.2</td>\n",
       "      <td>...</td>\n",
       "      <td>630</td>\n",
       "      <td>7.75</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>65.70</td>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400.0</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>133.9</td>\n",
       "      <td>...</td>\n",
       "      <td>450</td>\n",
       "      <td>6.33</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>97.5</td>\n",
       "      <td>...</td>\n",
       "      <td>540</td>\n",
       "      <td>8.53</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>65.97</td>\n",
       "      <td>6.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>107.2</td>\n",
       "      <td>...</td>\n",
       "      <td>540</td>\n",
       "      <td>7.75</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>65.65</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1        2       3    4           5      6      7        8     9   \\\n",
       "0     2558  1506.09  456.63   90   6395000.0  40.88   7.89  29780.0  0.19   \n",
       "1    22325    79.11  841.03  180  55812500.0  51.11   1.21  61900.0  0.02   \n",
       "2      115  1449.85  608.43   88    287500.0  40.42   7.34   3340.0  0.18   \n",
       "3     1201  1562.53  295.65   66   3002500.0  42.40   7.97  18030.0  0.19   \n",
       "4      312   950.27  440.86   37    780000.0  41.43   7.03   3350.0  0.17   \n",
       "..     ...      ...     ...  ...         ...    ...    ...      ...   ...   \n",
       "932     12    92.42  364.42  135     97200.0  59.42  10.34    884.0  0.17   \n",
       "933     11    98.82  248.64  159     89100.0  59.64  10.18    831.0  0.17   \n",
       "934     14    25.14  428.86   24    113400.0  60.14  17.94    847.0  0.30   \n",
       "935     10    96.00  451.30   68     81000.0  59.90  15.01    831.0  0.25   \n",
       "936     11     7.73  235.73  135     89100.0  61.82  12.24    831.0  0.20   \n",
       "\n",
       "        10  ...     35      37       40        41       42       43     44  \\\n",
       "0    214.7  ...  16110  138.68  2850.00   1000.00   763.16   135.46   3.73   \n",
       "1    901.7  ...  40140   68.65  5750.00  11500.00  9593.48  1648.80   0.60   \n",
       "2     86.1  ...   1530   38.80  1400.00    250.00   150.00    45.13   9.33   \n",
       "3    166.5  ...  10080  108.27  6041.52    761.58   453.21   144.97  13.33   \n",
       "4    232.8  ...   2340   14.39  1320.04    710.63   512.54   109.16   2.58   \n",
       "..     ...  ...    ...     ...      ...       ...      ...      ...    ...   \n",
       "932  110.0  ...    540    8.04   381.84    254.56    84.85   146.97   4.50   \n",
       "933  107.2  ...    630    7.75   284.60    180.00   150.00    51.96   1.90   \n",
       "934  133.9  ...    450    6.33   402.49    180.00   180.00     0.00   2.24   \n",
       "935   97.5  ...    540    8.53   402.49    180.00    90.00    73.48   4.47   \n",
       "936  107.2  ...    540    7.75   254.56    254.56   127.28   180.00   2.00   \n",
       "\n",
       "           46     47    48  \n",
       "0    33243.19  65.74  7.95  \n",
       "1    51572.04  65.73  6.26  \n",
       "2    31692.84  65.81  7.84  \n",
       "3    37696.21  65.67  8.07  \n",
       "4    29038.17  65.66  7.35  \n",
       "..        ...    ...   ...  \n",
       "932   2593.50  65.85  6.39  \n",
       "933   4361.25  65.70  6.53  \n",
       "934   2153.05  65.91  6.12  \n",
       "935   2421.43  65.97  6.32  \n",
       "936   3782.68  65.65  6.26  \n",
       "\n",
       "[937 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "932    0\n",
       "933    0\n",
       "934    0\n",
       "935    0\n",
       "936    0\n",
       "Name: 49, Length: 937, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X3)\n",
    "display(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.65085752\n",
      "Iteration 2, loss = 1.65085732\n",
      "Iteration 3, loss = 1.65085720\n",
      "Iteration 4, loss = 1.65085713\n",
      "Iteration 5, loss = 1.65085710\n",
      "Iteration 6, loss = 1.65085712\n",
      "Iteration 7, loss = 1.60186635\n",
      "Iteration 8, loss = 1.30466830\n",
      "Iteration 9, loss = 1.12609163\n",
      "Iteration 10, loss = 0.42349667\n",
      "Iteration 11, loss = 0.31457666\n",
      "Iteration 12, loss = 0.29997942\n",
      "Iteration 13, loss = 0.28552812\n",
      "Iteration 14, loss = 0.27155432\n",
      "Iteration 15, loss = 0.25946204\n",
      "Iteration 16, loss = 0.24851052\n",
      "Iteration 17, loss = 0.98595942\n",
      "Iteration 18, loss = 0.23241693\n",
      "Iteration 19, loss = 0.22646394\n",
      "Iteration 20, loss = 0.22121227\n",
      "Iteration 21, loss = 0.21633818\n",
      "Iteration 22, loss = 0.21242775\n",
      "Iteration 23, loss = 0.20886308\n",
      "Iteration 24, loss = 0.20577252\n",
      "Iteration 25, loss = 0.20343894\n",
      "Iteration 26, loss = 0.20113978\n",
      "Iteration 27, loss = 0.19940376\n",
      "Iteration 28, loss = 0.19774609\n",
      "Iteration 29, loss = 0.19653058\n",
      "Iteration 30, loss = 0.19538823\n",
      "Iteration 31, loss = 0.19447451\n",
      "Iteration 32, loss = 0.19352882\n",
      "Iteration 33, loss = 0.19275088\n",
      "Iteration 34, loss = 0.19193414\n",
      "Iteration 35, loss = 0.19134804\n",
      "Iteration 36, loss = 0.19071685\n",
      "Iteration 37, loss = 0.19020713\n",
      "Iteration 38, loss = 0.18977390\n",
      "Iteration 39, loss = 0.18933681\n",
      "Iteration 40, loss = 0.18900041\n",
      "Iteration 41, loss = 0.18872697\n",
      "Iteration 42, loss = 0.18836621\n",
      "Iteration 43, loss = 0.18812550\n",
      "Iteration 44, loss = 0.18792193\n",
      "Iteration 45, loss = 0.18768302\n",
      "Iteration 46, loss = 0.18749415\n",
      "Iteration 47, loss = 0.18736709\n",
      "Iteration 48, loss = 0.18715821\n",
      "Iteration 49, loss = 0.18699267\n",
      "Iteration 50, loss = 0.18682946\n",
      "Iteration 51, loss = 0.18674701\n",
      "Iteration 52, loss = 0.18664540\n",
      "Iteration 53, loss = 0.18659391\n",
      "Iteration 54, loss = 0.18656008\n",
      "Iteration 55, loss = 0.18652094\n",
      "Iteration 56, loss = 0.18649009\n",
      "Iteration 57, loss = 0.18643218\n",
      "Iteration 58, loss = 0.18642981\n",
      "Iteration 59, loss = 0.18635513\n",
      "Iteration 60, loss = 0.18629459\n",
      "Iteration 61, loss = 0.18628258\n",
      "Iteration 62, loss = 0.18622996\n",
      "Iteration 63, loss = 0.18618109\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(3, 2), learning_rate_init=0.01,\n",
       "              random_state=5, verbose=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = MLPClassifier(hidden_layer_sizes=(3,2),\n",
    "                    random_state=5,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.01)\n",
    "clf3.fit(X_train3,y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = clf3.predict(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 271                   0\n",
       "Actual Positive                  11                   0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the confusion matrix\n",
    "cm3 = metrics.confusion_matrix(y_test3, y_pred3)\n",
    "# Assigning columns names\n",
    "cm_df3 = pd.DataFrame(cm3, \n",
    "            columns = ['Predicted Negative', 'Predicted Positive'],\n",
    "            index = ['Actual Negative', 'Actual Positive'])\n",
    "# Showing the confusion matrix\n",
    "cm_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 0\n",
      "True Negatives: 271\n",
      "False Positives: 0\n",
      "False Negatives: 11\n",
      "Sensitivity: 0.0\n",
      "Precision = nan\n",
      "Negative Pred Value = 0.9609929078014184\n",
      "Specificity = 1.0\n",
      "Accuracy = 0.9609929078014184\n"
     ]
    }
   ],
   "source": [
    "sensitivity3,precision3,negativePredValues3,specificity3,accuracy3 = metric(cm3)\n",
    "sensitivityList.append(sensitivity3)\n",
    "precisionList.append(precision3)\n",
    "negativePredValuesList.append(negativePredValues3)\n",
    "specificityList.append(specificity3)\n",
    "accuracyList.append(accuracy3)\n",
    "print(f'Sensitivity: {sensitivity3}')\n",
    "print(f'Precision = {precision3}')\n",
    "print(f'Negative Pred Value = {negativePredValues3}')\n",
    "print(f'Specificity = {specificity3}')\n",
    "print(f'Accuracy = {accuracy3}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with low variance filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000.0</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500.0</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200.0</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>65.85</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>201</td>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>65.70</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400.0</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>203</td>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>65.97</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>204</td>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>65.65</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1        2       3    4           5      6      7        8   \\\n",
       "0      1   2558  1506.09  456.63   90   6395000.0  40.88   7.89  29780.0   \n",
       "1      2  22325    79.11  841.03  180  55812500.0  51.11   1.21  61900.0   \n",
       "2      3    115  1449.85  608.43   88    287500.0  40.42   7.34   3340.0   \n",
       "3      4   1201  1562.53  295.65   66   3002500.0  42.40   7.97  18030.0   \n",
       "4      5    312   950.27  440.86   37    780000.0  41.43   7.03   3350.0   \n",
       "..   ...    ...      ...     ...  ...         ...    ...    ...      ...   \n",
       "932  200     12    92.42  364.42  135     97200.0  59.42  10.34    884.0   \n",
       "933  201     11    98.82  248.64  159     89100.0  59.64  10.18    831.0   \n",
       "934  202     14    25.14  428.86   24    113400.0  60.14  17.94    847.0   \n",
       "935  203     10    96.00  451.30   68     81000.0  59.90  15.01    831.0   \n",
       "936  204     11     7.73  235.73  135     89100.0  61.82  12.24    831.0   \n",
       "\n",
       "       9   ...       40        41       42       43     44  45        46  \\\n",
       "0    0.19  ...  2850.00   1000.00   763.16   135.46   3.73   0  33243.19   \n",
       "1    0.02  ...  5750.00  11500.00  9593.48  1648.80   0.60   0  51572.04   \n",
       "2    0.18  ...  1400.00    250.00   150.00    45.13   9.33   1  31692.84   \n",
       "3    0.19  ...  6041.52    761.58   453.21   144.97  13.33   1  37696.21   \n",
       "4    0.17  ...  1320.04    710.63   512.54   109.16   2.58   0  29038.17   \n",
       "..    ...  ...      ...       ...      ...      ...    ...  ..       ...   \n",
       "932  0.17  ...   381.84    254.56    84.85   146.97   4.50   0   2593.50   \n",
       "933  0.17  ...   284.60    180.00   150.00    51.96   1.90   0   4361.25   \n",
       "934  0.30  ...   402.49    180.00   180.00     0.00   2.24   0   2153.05   \n",
       "935  0.25  ...   402.49    180.00    90.00    73.48   4.47   0   2421.43   \n",
       "936  0.20  ...   254.56    254.56   127.28   180.00   2.00   0   3782.68   \n",
       "\n",
       "        47    48  49  \n",
       "0    65.74  7.95   1  \n",
       "1    65.73  6.26   0  \n",
       "2    65.81  7.84   1  \n",
       "3    65.67  8.07   1  \n",
       "4    65.66  7.35   0  \n",
       "..     ...   ...  ..  \n",
       "932  65.85  6.39   0  \n",
       "933  65.70  6.53   0  \n",
       "934  65.91  6.12   0  \n",
       "935  65.97  6.32   0  \n",
       "936  65.65  6.26   0  \n",
       "\n",
       "[937 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data4 = pd.read_csv('./dataset/oil-spill.csv',header=None)\n",
    "display(data4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching and delete data with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 48) (937,)\n",
      "[0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5 ]\n",
      ">Threshold=0.00, Features=47\n",
      ">Threshold=0.05, Features=36\n",
      ">Threshold=0.10, Features=35\n",
      ">Threshold=0.15, Features=34\n",
      ">Threshold=0.20, Features=34\n",
      ">Threshold=0.25, Features=34\n",
      ">Threshold=0.30, Features=34\n",
      ">Threshold=0.35, Features=34\n",
      ">Threshold=0.40, Features=34\n",
      ">Threshold=0.45, Features=32\n",
      ">Threshold=0.50, Features=30\n",
      "[32, 34, 35, 36, 47, 30]\n"
     ]
    }
   ],
   "source": [
    "X4 = data4.iloc[:,1:-1]\n",
    "y4 = data4.iloc[:,-1]\n",
    "print(X4.shape, y4.shape)\n",
    "# define thresholds to check\n",
    "thresholds = np.arange(0.0, 0.55, 0.05)\n",
    "print(thresholds)\n",
    "# apply transform with each threshold\n",
    "results = []\n",
    "for t in thresholds:\n",
    "\t# define the transform\n",
    "\ttransform = VarianceThreshold(threshold=t)\n",
    "\t# transform the input data\n",
    "\tX_sel = transform.fit_transform(X4)\n",
    "\t# determine the number of input features\n",
    "\tn_features = X_sel.shape[1]\n",
    "\tprint('>Threshold=%.2f, Features=%d' % (t, n_features))\n",
    "\t# store the result\n",
    "\tresults.append(n_features)\n",
    "results = list(set(results))\n",
    "print(results)\n",
    "if data4.shape[1]-1 in results:\n",
    "    results.remove(data4.shape[1]-1)\n",
    "data4.drop(results, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000.0</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500.0</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200.0</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>201</td>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400.0</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>203</td>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>204</td>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1        2       3    4           5      6      7        8   \\\n",
       "0      1   2558  1506.09  456.63   90   6395000.0  40.88   7.89  29780.0   \n",
       "1      2  22325    79.11  841.03  180  55812500.0  51.11   1.21  61900.0   \n",
       "2      3    115  1449.85  608.43   88    287500.0  40.42   7.34   3340.0   \n",
       "3      4   1201  1562.53  295.65   66   3002500.0  42.40   7.97  18030.0   \n",
       "4      5    312   950.27  440.86   37    780000.0  41.43   7.03   3350.0   \n",
       "..   ...    ...      ...     ...  ...         ...    ...    ...      ...   \n",
       "932  200     12    92.42  364.42  135     97200.0  59.42  10.34    884.0   \n",
       "933  201     11    98.82  248.64  159     89100.0  59.64  10.18    831.0   \n",
       "934  202     14    25.14  428.86   24    113400.0  60.14  17.94    847.0   \n",
       "935  203     10    96.00  451.30   68     81000.0  59.90  15.01    831.0   \n",
       "936  204     11     7.73  235.73  135     89100.0  61.82  12.24    831.0   \n",
       "\n",
       "       9   ...  39       40        41       42       43     44  45        46  \\\n",
       "0    0.19  ...  69  2850.00   1000.00   763.16   135.46   3.73   0  33243.19   \n",
       "1    0.02  ...  69  5750.00  11500.00  9593.48  1648.80   0.60   0  51572.04   \n",
       "2    0.18  ...  69  1400.00    250.00   150.00    45.13   9.33   1  31692.84   \n",
       "3    0.19  ...  69  6041.52    761.58   453.21   144.97  13.33   1  37696.21   \n",
       "4    0.17  ...  69  1320.04    710.63   512.54   109.16   2.58   0  29038.17   \n",
       "..    ...  ...  ..      ...       ...      ...      ...    ...  ..       ...   \n",
       "932  0.17  ...  50   381.84    254.56    84.85   146.97   4.50   0   2593.50   \n",
       "933  0.17  ...  50   284.60    180.00   150.00    51.96   1.90   0   4361.25   \n",
       "934  0.30  ...  50   402.49    180.00   180.00     0.00   2.24   0   2153.05   \n",
       "935  0.25  ...  50   402.49    180.00    90.00    73.48   4.47   0   2421.43   \n",
       "936  0.20  ...  50   254.56    254.56   127.28   180.00   2.00   0   3782.68   \n",
       "\n",
       "       48  49  \n",
       "0    7.95   1  \n",
       "1    6.26   0  \n",
       "2    7.84   1  \n",
       "3    8.07   1  \n",
       "4    7.35   0  \n",
       "..    ...  ..  \n",
       "932  6.39   0  \n",
       "933  6.53   0  \n",
       "934  6.12   0  \n",
       "935  6.32   0  \n",
       "936  6.26   0  \n",
       "\n",
       "[937 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X4, y4, test_size=0.3, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2558</td>\n",
       "      <td>1506.09</td>\n",
       "      <td>456.63</td>\n",
       "      <td>90</td>\n",
       "      <td>6395000.0</td>\n",
       "      <td>40.88</td>\n",
       "      <td>7.89</td>\n",
       "      <td>29780.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>214.7</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>2850.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>763.16</td>\n",
       "      <td>135.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>33243.19</td>\n",
       "      <td>65.74</td>\n",
       "      <td>7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>901.7</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>5750.00</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>86.1</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201</td>\n",
       "      <td>1562.53</td>\n",
       "      <td>295.65</td>\n",
       "      <td>66</td>\n",
       "      <td>3002500.0</td>\n",
       "      <td>42.40</td>\n",
       "      <td>7.97</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>166.5</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>6041.52</td>\n",
       "      <td>761.58</td>\n",
       "      <td>453.21</td>\n",
       "      <td>144.97</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>37696.21</td>\n",
       "      <td>65.67</td>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312</td>\n",
       "      <td>950.27</td>\n",
       "      <td>440.86</td>\n",
       "      <td>37</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>41.43</td>\n",
       "      <td>7.03</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>232.8</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>1320.04</td>\n",
       "      <td>710.63</td>\n",
       "      <td>512.54</td>\n",
       "      <td>109.16</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "      <td>29038.17</td>\n",
       "      <td>65.66</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>12</td>\n",
       "      <td>92.42</td>\n",
       "      <td>364.42</td>\n",
       "      <td>135</td>\n",
       "      <td>97200.0</td>\n",
       "      <td>59.42</td>\n",
       "      <td>10.34</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>381.84</td>\n",
       "      <td>254.56</td>\n",
       "      <td>84.85</td>\n",
       "      <td>146.97</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2593.50</td>\n",
       "      <td>65.85</td>\n",
       "      <td>6.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>11</td>\n",
       "      <td>98.82</td>\n",
       "      <td>248.64</td>\n",
       "      <td>159</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>59.64</td>\n",
       "      <td>10.18</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>107.2</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>284.60</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>51.96</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>4361.25</td>\n",
       "      <td>65.70</td>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>428.86</td>\n",
       "      <td>24</td>\n",
       "      <td>113400.0</td>\n",
       "      <td>60.14</td>\n",
       "      <td>17.94</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>133.9</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>2153.05</td>\n",
       "      <td>65.91</td>\n",
       "      <td>6.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>10</td>\n",
       "      <td>96.00</td>\n",
       "      <td>451.30</td>\n",
       "      <td>68</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>59.90</td>\n",
       "      <td>15.01</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>97.5</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>402.49</td>\n",
       "      <td>180.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2421.43</td>\n",
       "      <td>65.97</td>\n",
       "      <td>6.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>11</td>\n",
       "      <td>7.73</td>\n",
       "      <td>235.73</td>\n",
       "      <td>135</td>\n",
       "      <td>89100.0</td>\n",
       "      <td>61.82</td>\n",
       "      <td>12.24</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>107.2</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>254.56</td>\n",
       "      <td>254.56</td>\n",
       "      <td>127.28</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3782.68</td>\n",
       "      <td>65.65</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1        2       3    4           5      6      7        8     9   \\\n",
       "0     2558  1506.09  456.63   90   6395000.0  40.88   7.89  29780.0  0.19   \n",
       "1    22325    79.11  841.03  180  55812500.0  51.11   1.21  61900.0  0.02   \n",
       "2      115  1449.85  608.43   88    287500.0  40.42   7.34   3340.0  0.18   \n",
       "3     1201  1562.53  295.65   66   3002500.0  42.40   7.97  18030.0  0.19   \n",
       "4      312   950.27  440.86   37    780000.0  41.43   7.03   3350.0  0.17   \n",
       "..     ...      ...     ...  ...         ...    ...    ...      ...   ...   \n",
       "932     12    92.42  364.42  135     97200.0  59.42  10.34    884.0  0.17   \n",
       "933     11    98.82  248.64  159     89100.0  59.64  10.18    831.0  0.17   \n",
       "934     14    25.14  428.86   24    113400.0  60.14  17.94    847.0  0.30   \n",
       "935     10    96.00  451.30   68     81000.0  59.90  15.01    831.0  0.25   \n",
       "936     11     7.73  235.73  135     89100.0  61.82  12.24    831.0  0.20   \n",
       "\n",
       "        10  ...  39       40        41       42       43     44  45        46  \\\n",
       "0    214.7  ...  69  2850.00   1000.00   763.16   135.46   3.73   0  33243.19   \n",
       "1    901.7  ...  69  5750.00  11500.00  9593.48  1648.80   0.60   0  51572.04   \n",
       "2     86.1  ...  69  1400.00    250.00   150.00    45.13   9.33   1  31692.84   \n",
       "3    166.5  ...  69  6041.52    761.58   453.21   144.97  13.33   1  37696.21   \n",
       "4    232.8  ...  69  1320.04    710.63   512.54   109.16   2.58   0  29038.17   \n",
       "..     ...  ...  ..      ...       ...      ...      ...    ...  ..       ...   \n",
       "932  110.0  ...  50   381.84    254.56    84.85   146.97   4.50   0   2593.50   \n",
       "933  107.2  ...  50   284.60    180.00   150.00    51.96   1.90   0   4361.25   \n",
       "934  133.9  ...  50   402.49    180.00   180.00     0.00   2.24   0   2153.05   \n",
       "935   97.5  ...  50   402.49    180.00    90.00    73.48   4.47   0   2421.43   \n",
       "936  107.2  ...  50   254.56    254.56   127.28   180.00   2.00   0   3782.68   \n",
       "\n",
       "        47    48  \n",
       "0    65.74  7.95  \n",
       "1    65.73  6.26  \n",
       "2    65.81  7.84  \n",
       "3    65.67  8.07  \n",
       "4    65.66  7.35  \n",
       "..     ...   ...  \n",
       "932  65.85  6.39  \n",
       "933  65.70  6.53  \n",
       "934  65.91  6.12  \n",
       "935  65.97  6.32  \n",
       "936  65.65  6.26  \n",
       "\n",
       "[937 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "932    0\n",
       "933    0\n",
       "934    0\n",
       "935    0\n",
       "936    0\n",
       "Name: 49, Length: 937, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X4)\n",
    "display(y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.65085773\n",
      "Iteration 2, loss = 1.65085744\n",
      "Iteration 3, loss = 1.65085719\n",
      "Iteration 4, loss = 1.65085698\n",
      "Iteration 5, loss = 1.65085681\n",
      "Iteration 6, loss = 1.65085669\n",
      "Iteration 7, loss = 0.86697357\n",
      "Iteration 8, loss = 0.99590256\n",
      "Iteration 9, loss = 0.83534846\n",
      "Iteration 10, loss = 0.81142514\n",
      "Iteration 11, loss = 0.78619496\n",
      "Iteration 12, loss = 0.76093726\n",
      "Iteration 13, loss = 0.73651801\n",
      "Iteration 14, loss = 0.71305993\n",
      "Iteration 15, loss = 0.69071840\n",
      "Iteration 16, loss = 0.66924031\n",
      "Iteration 17, loss = 0.72025822\n",
      "Iteration 18, loss = 0.63134014\n",
      "Iteration 19, loss = 0.61406549\n",
      "Iteration 20, loss = 0.59715168\n",
      "Iteration 21, loss = 0.58079146\n",
      "Iteration 22, loss = 0.56518377\n",
      "Iteration 23, loss = 0.55006947\n",
      "Iteration 24, loss = 0.53563571\n",
      "Iteration 25, loss = 0.52194142\n",
      "Iteration 26, loss = 0.50891511\n",
      "Iteration 27, loss = 0.49651971\n",
      "Iteration 28, loss = 0.48467442\n",
      "Iteration 29, loss = 0.47339596\n",
      "Iteration 30, loss = 0.46253329\n",
      "Iteration 31, loss = 0.45208511\n",
      "Iteration 32, loss = 0.44216188\n",
      "Iteration 33, loss = 0.43272812\n",
      "Iteration 34, loss = 0.42344956\n",
      "Iteration 35, loss = 0.41484394\n",
      "Iteration 36, loss = 0.40643360\n",
      "Iteration 37, loss = 0.39835529\n",
      "Iteration 38, loss = 0.39073867\n",
      "Iteration 39, loss = 0.38352360\n",
      "Iteration 40, loss = 0.37644407\n",
      "Iteration 41, loss = 0.36983900\n",
      "Iteration 42, loss = 0.36333993\n",
      "Iteration 43, loss = 0.35715897\n",
      "Iteration 44, loss = 0.35120570\n",
      "Iteration 45, loss = 0.34546974\n",
      "Iteration 46, loss = 0.33997660\n",
      "Iteration 47, loss = 0.33466266\n",
      "Iteration 48, loss = 0.32957474\n",
      "Iteration 49, loss = 0.32459617\n",
      "Iteration 50, loss = 0.31996272\n",
      "Iteration 51, loss = 0.31559817\n",
      "Iteration 52, loss = 0.31135103\n",
      "Iteration 53, loss = 0.30734521\n",
      "Iteration 54, loss = 0.30332110\n",
      "Iteration 55, loss = 0.29963219\n",
      "Iteration 56, loss = 0.29593949\n",
      "Iteration 57, loss = 0.29247802\n",
      "Iteration 58, loss = 0.28905213\n",
      "Iteration 59, loss = 0.28578994\n",
      "Iteration 60, loss = 0.28271512\n",
      "Iteration 61, loss = 0.27967279\n",
      "Iteration 62, loss = 0.27675190\n",
      "Iteration 63, loss = 0.27386708\n",
      "Iteration 64, loss = 0.27109495\n",
      "Iteration 65, loss = 0.26846277\n",
      "Iteration 66, loss = 0.26585136\n",
      "Iteration 67, loss = 0.26329558\n",
      "Iteration 68, loss = 0.26085495\n",
      "Iteration 69, loss = 0.25853214\n",
      "Iteration 70, loss = 0.25619645\n",
      "Iteration 71, loss = 0.25407203\n",
      "Iteration 72, loss = 0.25195191\n",
      "Iteration 73, loss = 0.24994772\n",
      "Iteration 74, loss = 0.24798603\n",
      "Iteration 75, loss = 0.24608581\n",
      "Iteration 76, loss = 0.24438176\n",
      "Iteration 77, loss = 0.24263180\n",
      "Iteration 78, loss = 0.24100170\n",
      "Iteration 79, loss = 0.23939354\n",
      "Iteration 80, loss = 0.23782767\n",
      "Iteration 81, loss = 0.23627446\n",
      "Iteration 82, loss = 0.23477384\n",
      "Iteration 83, loss = 0.23331621\n",
      "Iteration 84, loss = 0.23195559\n",
      "Iteration 85, loss = 0.23057823\n",
      "Iteration 86, loss = 0.22930748\n",
      "Iteration 87, loss = 0.22809984\n",
      "Iteration 88, loss = 0.22689516\n",
      "Iteration 89, loss = 0.22577605\n",
      "Iteration 90, loss = 0.22463884\n",
      "Iteration 91, loss = 0.22353662\n",
      "Iteration 92, loss = 0.22240974\n",
      "Iteration 93, loss = 0.22133467\n",
      "Iteration 94, loss = 0.22031807\n",
      "Iteration 95, loss = 0.21933730\n",
      "Iteration 96, loss = 0.21838487\n",
      "Iteration 97, loss = 0.21743896\n",
      "Iteration 98, loss = 0.21652427\n",
      "Iteration 99, loss = 0.21563335\n",
      "Iteration 100, loss = 0.21477909\n",
      "Iteration 101, loss = 0.21393644\n",
      "Iteration 102, loss = 0.21314303\n",
      "Iteration 103, loss = 0.21234443\n",
      "Iteration 104, loss = 0.21154857\n",
      "Iteration 105, loss = 0.21083824\n",
      "Iteration 106, loss = 0.21010717\n",
      "Iteration 107, loss = 0.20935932\n",
      "Iteration 108, loss = 0.20868767\n",
      "Iteration 109, loss = 0.20803770\n",
      "Iteration 110, loss = 0.20740471\n",
      "Iteration 111, loss = 0.20681522\n",
      "Iteration 112, loss = 0.50825385\n",
      "Iteration 113, loss = 0.20578379\n",
      "Iteration 114, loss = 0.20528469\n",
      "Iteration 115, loss = 0.20478846\n",
      "Iteration 116, loss = 0.20426169\n",
      "Iteration 117, loss = 0.20379440\n",
      "Iteration 118, loss = 0.20330632\n",
      "Iteration 119, loss = 0.20284685\n",
      "Iteration 120, loss = 0.20239118\n",
      "Iteration 121, loss = 0.20197316\n",
      "Iteration 122, loss = 0.20157585\n",
      "Iteration 123, loss = 0.20117170\n",
      "Iteration 124, loss = 0.20078773\n",
      "Iteration 125, loss = 0.20039545\n",
      "Iteration 126, loss = 0.20005223\n",
      "Iteration 127, loss = 0.19968365\n",
      "Iteration 128, loss = 0.19932987\n",
      "Iteration 129, loss = 0.19892002\n",
      "Iteration 130, loss = 0.19856968\n",
      "Iteration 131, loss = 0.19821130\n",
      "Iteration 132, loss = 0.19784874\n",
      "Iteration 133, loss = 0.19755397\n",
      "Iteration 134, loss = 0.19720278\n",
      "Iteration 135, loss = 0.19688583\n",
      "Iteration 136, loss = 0.19662886\n",
      "Iteration 137, loss = 0.19634118\n",
      "Iteration 138, loss = 0.19607119\n",
      "Iteration 139, loss = 0.19578557\n",
      "Iteration 140, loss = 0.19554990\n",
      "Iteration 141, loss = 0.19528022\n",
      "Iteration 142, loss = 0.19501306\n",
      "Iteration 143, loss = 0.19476784\n",
      "Iteration 144, loss = 0.19453613\n",
      "Iteration 145, loss = 0.19429066\n",
      "Iteration 146, loss = 0.19404301\n",
      "Iteration 147, loss = 0.19382028\n",
      "Iteration 148, loss = 0.19361716\n",
      "Iteration 149, loss = 0.19340025\n",
      "Iteration 150, loss = 0.19321465\n",
      "Iteration 151, loss = 0.19298813\n",
      "Iteration 152, loss = 0.19280021\n",
      "Iteration 153, loss = 0.19257297\n",
      "Iteration 154, loss = 0.19240884\n",
      "Iteration 155, loss = 0.19224338\n",
      "Iteration 156, loss = 0.19202939\n",
      "Iteration 157, loss = 0.19189179\n",
      "Iteration 158, loss = 0.19168935\n",
      "Iteration 159, loss = 0.19153786\n",
      "Iteration 160, loss = 0.19135192\n",
      "Iteration 161, loss = 0.19121186\n",
      "Iteration 162, loss = 0.19104249\n",
      "Iteration 163, loss = 0.19090742\n",
      "Iteration 164, loss = 0.19078626\n",
      "Iteration 165, loss = 0.19064729\n",
      "Iteration 166, loss = 0.19053445\n",
      "Iteration 167, loss = 0.19042343\n",
      "Iteration 168, loss = 0.19031191\n",
      "Iteration 169, loss = 0.19020063\n",
      "Iteration 170, loss = 0.19010244\n",
      "Iteration 171, loss = 0.19001714\n",
      "Iteration 172, loss = 0.18991126\n",
      "Iteration 173, loss = 0.18980709\n",
      "Iteration 174, loss = 0.18972442\n",
      "Iteration 175, loss = 0.18963234\n",
      "Iteration 176, loss = 0.18952675\n",
      "Iteration 177, loss = 0.18943039\n",
      "Iteration 178, loss = 0.18931718\n",
      "Iteration 179, loss = 0.18924147\n",
      "Iteration 180, loss = 0.18915536\n",
      "Iteration 181, loss = 0.18908196\n",
      "Iteration 182, loss = 0.18901366\n",
      "Iteration 183, loss = 0.18895131\n",
      "Iteration 184, loss = 0.18884801\n",
      "Iteration 185, loss = 0.18877946\n",
      "Iteration 186, loss = 0.18870447\n",
      "Iteration 187, loss = 0.18862401\n",
      "Iteration 188, loss = 0.18854954\n",
      "Iteration 189, loss = 0.18848778\n",
      "Iteration 190, loss = 0.18843403\n",
      "Iteration 191, loss = 0.18834229\n",
      "Iteration 192, loss = 0.18830491\n",
      "Iteration 193, loss = 0.18823427\n",
      "Iteration 194, loss = 0.18818757\n",
      "Iteration 195, loss = 0.18813549\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(3, 2), learning_rate_init=0.01,\n",
       "              random_state=5, verbose=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4 = MLPClassifier(hidden_layer_sizes=(3,2),\n",
    "                    random_state=5,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.01)\n",
    "clf4.fit(X_train4,y_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = clf4.predict(X_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 271                   0\n",
       "Actual Positive                  11                   0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the confusion matrix\n",
    "cm4 = metrics.confusion_matrix(y_test4, y_pred4)\n",
    "# Assigning columns names\n",
    "cm_df4 = pd.DataFrame(cm4, \n",
    "            columns = ['Predicted Negative', 'Predicted Positive'],\n",
    "            index = ['Actual Negative', 'Actual Positive'])\n",
    "# Showing the confusion matrix\n",
    "cm_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 0\n",
      "True Negatives: 271\n",
      "False Positives: 0\n",
      "False Negatives: 11\n",
      "Sensitivity: 0.0\n",
      "Precision = nan\n",
      "Negative Pred Value = 0.9609929078014184\n",
      "Specificity = 1.0\n",
      "Accuracy = 0.9609929078014184\n"
     ]
    }
   ],
   "source": [
    "sensitivity4,precision4,negativePredValues4,specificity4,accuracy4 = metric(cm4)\n",
    "sensitivityList.append(sensitivity4)\n",
    "precisionList.append(precision4)\n",
    "negativePredValuesList.append(negativePredValues4)\n",
    "specificityList.append(specificity4)\n",
    "accuracyList.append(accuracy4)\n",
    "print(f'Sensitivity: {sensitivity4}')\n",
    "print(f'Precision = {precision4}')\n",
    "print(f'Negative Pred Value = {negativePredValues4}')\n",
    "print(f'Specificity = {specificity4}')\n",
    "print(f'Accuracy = {accuracy4}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without any data cleansing - data 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
       "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataIris1 = pd.read_csv(\"./dataset/iris.csv\",header=None)\n",
    "display(dataIris1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3\n",
       "0    3.5  1.4  0.2\n",
       "1    3.0  1.4  0.2\n",
       "2    3.2  1.3  0.2\n",
       "3    3.1  1.5  0.2\n",
       "4    3.6  1.4  0.2\n",
       "..   ...  ...  ...\n",
       "145  3.0  5.2  2.3\n",
       "146  2.5  5.0  1.9\n",
       "147  3.0  5.2  2.0\n",
       "148  3.4  5.4  2.3\n",
       "149  3.0  5.1  1.8\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0         Iris-setosa\n",
       "1         Iris-setosa\n",
       "2         Iris-setosa\n",
       "3         Iris-setosa\n",
       "4         Iris-setosa\n",
       "            ...      \n",
       "145    Iris-virginica\n",
       "146    Iris-virginica\n",
       "147    Iris-virginica\n",
       "148    Iris-virginica\n",
       "149    Iris-virginica\n",
       "Name: 4, Length: 150, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xiris1 = dataIris1.iloc[:,1:-1]\n",
    "yiris1 = dataIris1.iloc[:,-1]\n",
    "display(Xiris1)\n",
    "display(yiris1)\n",
    "\n",
    "X_trainIris1, X_testIris1, y_trainIris1, y_testIris1 = train_test_split(Xiris1, yiris1, test_size=0.3, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.05044168\n",
      "Iteration 2, loss = 1.03149909\n",
      "Iteration 3, loss = 1.01210506\n",
      "Iteration 4, loss = 0.99228537\n",
      "Iteration 5, loss = 0.97207322\n",
      "Iteration 6, loss = 0.95151007\n",
      "Iteration 7, loss = 0.93064627\n",
      "Iteration 8, loss = 0.90954155\n",
      "Iteration 9, loss = 0.88834003\n",
      "Iteration 10, loss = 0.86710415\n",
      "Iteration 11, loss = 0.84607377\n",
      "Iteration 12, loss = 0.82534217\n",
      "Iteration 13, loss = 0.80513986\n",
      "Iteration 14, loss = 0.78593566\n",
      "Iteration 15, loss = 0.76800851\n",
      "Iteration 16, loss = 0.75140423\n",
      "Iteration 17, loss = 0.73598212\n",
      "Iteration 18, loss = 0.72157025\n",
      "Iteration 19, loss = 0.70828845\n",
      "Iteration 20, loss = 0.69612489\n",
      "Iteration 21, loss = 0.68497390\n",
      "Iteration 22, loss = 0.67489929\n",
      "Iteration 23, loss = 0.66568388\n",
      "Iteration 24, loss = 0.65731828\n",
      "Iteration 25, loss = 0.64968849\n",
      "Iteration 26, loss = 0.64274211\n",
      "Iteration 27, loss = 0.63644572\n",
      "Iteration 28, loss = 0.63074600\n",
      "Iteration 29, loss = 0.62560164\n",
      "Iteration 30, loss = 0.62092928\n",
      "Iteration 31, loss = 0.61672277\n",
      "Iteration 32, loss = 0.61288447\n",
      "Iteration 33, loss = 0.60936317\n",
      "Iteration 34, loss = 0.60612012\n",
      "Iteration 35, loss = 0.60309400\n",
      "Iteration 36, loss = 0.60027118\n",
      "Iteration 37, loss = 0.59764237\n",
      "Iteration 38, loss = 0.59517940\n",
      "Iteration 39, loss = 0.59284025\n",
      "Iteration 40, loss = 0.59060456\n",
      "Iteration 41, loss = 0.58845936\n",
      "Iteration 42, loss = 0.58639480\n",
      "Iteration 43, loss = 0.58439767\n",
      "Iteration 44, loss = 0.58246022\n",
      "Iteration 45, loss = 0.58057777\n",
      "Iteration 46, loss = 0.57874666\n",
      "Iteration 47, loss = 0.57697926\n",
      "Iteration 48, loss = 0.57525759\n",
      "Iteration 49, loss = 0.57357967\n",
      "Iteration 50, loss = 0.57194398\n",
      "Iteration 51, loss = 0.57034936\n",
      "Iteration 52, loss = 0.56880914\n",
      "Iteration 53, loss = 0.56733375\n",
      "Iteration 54, loss = 0.56590424\n",
      "Iteration 55, loss = 0.56450782\n",
      "Iteration 56, loss = 0.56314915\n",
      "Iteration 57, loss = 0.56181809\n",
      "Iteration 58, loss = 0.56052580\n",
      "Iteration 59, loss = 0.55926576\n",
      "Iteration 60, loss = 0.55803440\n",
      "Iteration 61, loss = 0.55683027\n",
      "Iteration 62, loss = 0.55565193\n",
      "Iteration 63, loss = 0.55448693\n",
      "Iteration 64, loss = 0.55333357\n",
      "Iteration 65, loss = 0.55219390\n",
      "Iteration 66, loss = 0.55106953\n",
      "Iteration 67, loss = 0.54996023\n",
      "Iteration 68, loss = 0.54886538\n",
      "Iteration 69, loss = 0.54778442\n",
      "Iteration 70, loss = 0.54671277\n",
      "Iteration 71, loss = 0.54564678\n",
      "Iteration 72, loss = 0.54458356\n",
      "Iteration 73, loss = 0.54352031\n",
      "Iteration 74, loss = 0.54246073\n",
      "Iteration 75, loss = 0.54140679\n",
      "Iteration 76, loss = 0.54035716\n",
      "Iteration 77, loss = 0.53932137\n",
      "Iteration 78, loss = 0.53827776\n",
      "Iteration 79, loss = 0.53713731\n",
      "Iteration 80, loss = 0.53576178\n",
      "Iteration 81, loss = 0.53322118\n",
      "Iteration 82, loss = 0.52936302\n",
      "Iteration 83, loss = 0.52687055\n",
      "Iteration 84, loss = 0.52590914\n",
      "Iteration 85, loss = 0.52358255\n",
      "Iteration 86, loss = 0.52020126\n",
      "Iteration 87, loss = 0.51695961\n",
      "Iteration 88, loss = 0.51469237\n",
      "Iteration 89, loss = 0.51189629\n",
      "Iteration 90, loss = 0.50793310\n",
      "Iteration 91, loss = 0.50302836\n",
      "Iteration 92, loss = 0.49729840\n",
      "Iteration 93, loss = 0.48981450\n",
      "Iteration 94, loss = 0.48022896\n",
      "Iteration 95, loss = 0.47137535\n",
      "Iteration 96, loss = 0.46512390\n",
      "Iteration 97, loss = 0.45811289\n",
      "Iteration 98, loss = 0.45040798\n",
      "Iteration 99, loss = 0.44291390\n",
      "Iteration 100, loss = 0.43502290\n",
      "Iteration 101, loss = 0.42679432\n",
      "Iteration 102, loss = 0.41853520\n",
      "Iteration 103, loss = 0.41021766\n",
      "Iteration 104, loss = 0.40180617\n",
      "Iteration 105, loss = 0.39344640\n",
      "Iteration 106, loss = 0.38499900\n",
      "Iteration 107, loss = 0.37654317\n",
      "Iteration 108, loss = 0.36800498\n",
      "Iteration 109, loss = 0.35938725\n",
      "Iteration 110, loss = 0.35085945\n",
      "Iteration 111, loss = 0.34263711\n",
      "Iteration 112, loss = 0.33423797\n",
      "Iteration 113, loss = 0.32631114\n",
      "Iteration 114, loss = 0.31804383\n",
      "Iteration 115, loss = 0.31048712\n",
      "Iteration 116, loss = 0.30236224\n",
      "Iteration 117, loss = 0.29522007\n",
      "Iteration 118, loss = 0.28789365\n",
      "Iteration 119, loss = 0.28065706\n",
      "Iteration 120, loss = 0.27443109\n",
      "Iteration 121, loss = 0.26734930\n",
      "Iteration 122, loss = 0.26113038\n",
      "Iteration 123, loss = 0.25464474\n",
      "Iteration 124, loss = 0.24869898\n",
      "Iteration 125, loss = 0.24320620\n",
      "Iteration 126, loss = 0.23760110\n",
      "Iteration 127, loss = 0.23251875\n",
      "Iteration 128, loss = 0.22751004\n",
      "Iteration 129, loss = 0.22244436\n",
      "Iteration 130, loss = 0.21763246\n",
      "Iteration 131, loss = 0.21310638\n",
      "Iteration 132, loss = 0.20855708\n",
      "Iteration 133, loss = 0.20441316\n",
      "Iteration 134, loss = 0.20054197\n",
      "Iteration 135, loss = 0.19639563\n",
      "Iteration 136, loss = 0.19294832\n",
      "Iteration 137, loss = 0.18923910\n",
      "Iteration 138, loss = 0.18575925\n",
      "Iteration 139, loss = 0.18258536\n",
      "Iteration 140, loss = 0.17932165\n",
      "Iteration 141, loss = 0.17636457\n",
      "Iteration 142, loss = 0.17348560\n",
      "Iteration 143, loss = 0.17060753\n",
      "Iteration 144, loss = 0.16793999\n",
      "Iteration 145, loss = 0.16532789\n",
      "Iteration 146, loss = 0.16286777\n",
      "Iteration 147, loss = 0.16052304\n",
      "Iteration 148, loss = 0.15817055\n",
      "Iteration 149, loss = 0.15605133\n",
      "Iteration 150, loss = 0.15388735\n",
      "Iteration 151, loss = 0.15173253\n",
      "Iteration 152, loss = 0.14984987\n",
      "Iteration 153, loss = 0.14790474\n",
      "Iteration 154, loss = 0.14600502\n",
      "Iteration 155, loss = 0.14427871\n",
      "Iteration 156, loss = 0.14253670\n",
      "Iteration 157, loss = 0.14085757\n",
      "Iteration 158, loss = 0.13934055\n",
      "Iteration 159, loss = 0.13782888\n",
      "Iteration 160, loss = 0.13626329\n",
      "Iteration 161, loss = 0.13469535\n",
      "Iteration 162, loss = 0.13342045\n",
      "Iteration 163, loss = 0.13209464\n",
      "Iteration 164, loss = 0.13068815\n",
      "Iteration 165, loss = 0.12936375\n",
      "Iteration 166, loss = 0.12816857\n",
      "Iteration 167, loss = 0.12698074\n",
      "Iteration 168, loss = 0.12571860\n",
      "Iteration 169, loss = 0.12457575\n",
      "Iteration 170, loss = 0.12346748\n",
      "Iteration 171, loss = 0.12240704\n",
      "Iteration 172, loss = 0.12136549\n",
      "Iteration 173, loss = 0.12034848\n",
      "Iteration 174, loss = 0.11931566\n",
      "Iteration 175, loss = 0.11834146\n",
      "Iteration 176, loss = 0.11739052\n",
      "Iteration 177, loss = 0.11647326\n",
      "Iteration 178, loss = 0.11564759\n",
      "Iteration 179, loss = 0.11475766\n",
      "Iteration 180, loss = 0.11385193\n",
      "Iteration 181, loss = 0.11300122\n",
      "Iteration 182, loss = 0.11216875\n",
      "Iteration 183, loss = 0.11142098\n",
      "Iteration 184, loss = 0.11057177\n",
      "Iteration 185, loss = 0.10985195\n",
      "Iteration 186, loss = 0.10910691\n",
      "Iteration 187, loss = 0.10837209\n",
      "Iteration 188, loss = 0.10763440\n",
      "Iteration 189, loss = 0.10690393\n",
      "Iteration 190, loss = 0.10625461\n",
      "Iteration 191, loss = 0.10554497\n",
      "Iteration 192, loss = 0.10492136\n",
      "Iteration 193, loss = 0.10430601\n",
      "Iteration 194, loss = 0.10370025\n",
      "Iteration 195, loss = 0.10308504\n",
      "Iteration 196, loss = 0.10249341\n",
      "Iteration 197, loss = 0.10188467\n",
      "Iteration 198, loss = 0.10130785\n",
      "Iteration 199, loss = 0.10071955\n",
      "Iteration 200, loss = 0.10016099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(3, 2), learning_rate_init=0.01,\n",
       "              random_state=5, verbose=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfIris1 = MLPClassifier(hidden_layer_sizes=(3,2),\n",
    "                    random_state=5,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.01)\n",
    "clfIris1.fit(X_trainIris1,y_trainIris1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predIris1 = clfIris1.predict(X_testIris1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-setosa</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "Iris-setosa               19                0               0\n",
       "Iris-versicolor            0               12               1\n",
       "Iris-virginica             0                0              13"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastCol = dataIris1.shape[1]-1\n",
    "uniqueOutputs = dataIris1[lastCol].unique().tolist()\n",
    "# Creating the confusion matrix\n",
    "cmIris1 = metrics.confusion_matrix(y_testIris1, y_predIris1)\n",
    "# Assigning columns names\n",
    "cm_dfIris1 = pd.DataFrame(cmIris1, \n",
    "            columns = uniqueOutputs,\n",
    "            index = uniqueOutputs)\n",
    "# Showing the confusion matrix\n",
    "cm_dfIris1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(cm):\n",
    "    TP = cm[0][0]\n",
    "    FN = (cm[0,1:]).sum()\n",
    "    FP = (cm[1:,0]).sum()\n",
    "    TN = (cm[1:,1:]).flatten().sum()\n",
    "    sensitivity = ((TP / (TP+FN)))\n",
    "    precision = ((TP/(TP+FP)))\n",
    "    negativePredValues = (TN/(TN+FN))\n",
    "    specificity = (TN / (TN+FP))\n",
    "    accuracy = ((TP+TN)/(TP+TN+FP+FN))\n",
    "    print('True Positives:', TP)\n",
    "    print('True Negatives:', TN)\n",
    "    print('False Positives:', FP)\n",
    "    print('False Negatives:', FN)\n",
    "    return sensitivity,precision,negativePredValues,specificity,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 19\n",
      "True Negatives: 26\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Sensitivity: 1.0\n",
      "Precision = 1.0\n",
      "Negative Pred Value = 1.0\n",
      "Specificity = 1.0\n",
      "Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "sensitivityiris1,precisioniris1,negativePredValuesiris1,specificityiris1,accuracyiris1 = metric(cmIris1)\n",
    "sensitivityList.append(sensitivityiris1)\n",
    "precisionList.append(precisioniris1)\n",
    "negativePredValuesList.append(negativePredValuesiris1)\n",
    "specificityList.append(specificityiris1)\n",
    "accuracyList.append(accuracyiris1)\n",
    "print(f'Sensitivity: {sensitivityiris1}')\n",
    "print(f'Precision = {precisioniris1}')\n",
    "print(f'Negative Pred Value = {negativePredValuesiris1}')\n",
    "print(f'Specificity = {specificityiris1}')\n",
    "print(f'Accuracy = {accuracyiris1}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with duplicated filter - data 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
       "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataIris2 = pd.read_csv(\"./dataset/iris.csv\",header=None)\n",
    "display(dataIris2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
       "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[147 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataIris2.drop_duplicates(inplace=True)\n",
    "display(dataIris2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3\n",
       "0    3.5  1.4  0.2\n",
       "1    3.0  1.4  0.2\n",
       "2    3.2  1.3  0.2\n",
       "3    3.1  1.5  0.2\n",
       "4    3.6  1.4  0.2\n",
       "..   ...  ...  ...\n",
       "145  3.0  5.2  2.3\n",
       "146  2.5  5.0  1.9\n",
       "147  3.0  5.2  2.0\n",
       "148  3.4  5.4  2.3\n",
       "149  3.0  5.1  1.8\n",
       "\n",
       "[147 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0         Iris-setosa\n",
       "1         Iris-setosa\n",
       "2         Iris-setosa\n",
       "3         Iris-setosa\n",
       "4         Iris-setosa\n",
       "            ...      \n",
       "145    Iris-virginica\n",
       "146    Iris-virginica\n",
       "147    Iris-virginica\n",
       "148    Iris-virginica\n",
       "149    Iris-virginica\n",
       "Name: 4, Length: 147, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xiris2 = dataIris2.iloc[:,1:-1]\n",
    "yiris2 = dataIris2.iloc[:,-1]\n",
    "display(Xiris2)\n",
    "display(yiris2)\n",
    "\n",
    "X_trainIris2, X_testIris2, y_trainIris2, y_testIris2 = train_test_split(Xiris2, yiris2, test_size=0.3, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.05182856\n",
      "Iteration 2, loss = 1.03214129\n",
      "Iteration 3, loss = 1.01202892\n",
      "Iteration 4, loss = 0.99152237\n",
      "Iteration 5, loss = 0.97065999\n",
      "Iteration 6, loss = 0.94949710\n",
      "Iteration 7, loss = 0.92812769\n",
      "Iteration 8, loss = 0.90656930\n",
      "Iteration 9, loss = 0.88500567\n",
      "Iteration 10, loss = 0.86348583\n",
      "Iteration 11, loss = 0.84218355\n",
      "Iteration 12, loss = 0.82127152\n",
      "Iteration 13, loss = 0.80102594\n",
      "Iteration 14, loss = 0.78161614\n",
      "Iteration 15, loss = 0.76330316\n",
      "Iteration 16, loss = 0.74614197\n",
      "Iteration 17, loss = 0.73000244\n",
      "Iteration 18, loss = 0.71502243\n",
      "Iteration 19, loss = 0.70127563\n",
      "Iteration 20, loss = 0.68865051\n",
      "Iteration 21, loss = 0.67716057\n",
      "Iteration 22, loss = 0.66665739\n",
      "Iteration 23, loss = 0.65706813\n",
      "Iteration 24, loss = 0.64822359\n",
      "Iteration 25, loss = 0.64013673\n",
      "Iteration 26, loss = 0.63279323\n",
      "Iteration 27, loss = 0.62608522\n",
      "Iteration 28, loss = 0.62000107\n",
      "Iteration 29, loss = 0.61447985\n",
      "Iteration 30, loss = 0.60948765\n",
      "Iteration 31, loss = 0.60498191\n",
      "Iteration 32, loss = 0.60092037\n",
      "Iteration 33, loss = 0.59726186\n",
      "Iteration 34, loss = 0.59393717\n",
      "Iteration 35, loss = 0.59089521\n",
      "Iteration 36, loss = 0.58808665\n",
      "Iteration 37, loss = 0.58547334\n",
      "Iteration 38, loss = 0.58303733\n",
      "Iteration 39, loss = 0.58077388\n",
      "Iteration 40, loss = 0.57863319\n",
      "Iteration 41, loss = 0.57659366\n",
      "Iteration 42, loss = 0.57464009\n",
      "Iteration 43, loss = 0.57275890\n",
      "Iteration 44, loss = 0.57094372\n",
      "Iteration 45, loss = 0.56920462\n",
      "Iteration 46, loss = 0.56751857\n",
      "Iteration 47, loss = 0.56587965\n",
      "Iteration 48, loss = 0.56428392\n",
      "Iteration 49, loss = 0.56274506\n",
      "Iteration 50, loss = 0.56131722\n",
      "Iteration 51, loss = 0.55993952\n",
      "Iteration 52, loss = 0.55858860\n",
      "Iteration 53, loss = 0.55726463\n",
      "Iteration 54, loss = 0.55596867\n",
      "Iteration 55, loss = 0.55469887\n",
      "Iteration 56, loss = 0.55345569\n",
      "Iteration 57, loss = 0.55223785\n",
      "Iteration 58, loss = 0.55104117\n",
      "Iteration 59, loss = 0.54986055\n",
      "Iteration 60, loss = 0.54869859\n",
      "Iteration 61, loss = 0.54755261\n",
      "Iteration 62, loss = 0.54642262\n",
      "Iteration 63, loss = 0.54530834\n",
      "Iteration 64, loss = 0.54421004\n",
      "Iteration 65, loss = 0.54312604\n",
      "Iteration 66, loss = 0.54205597\n",
      "Iteration 67, loss = 0.54100093\n",
      "Iteration 68, loss = 0.53996826\n",
      "Iteration 69, loss = 0.53895214\n",
      "Iteration 70, loss = 0.53794734\n",
      "Iteration 71, loss = 0.53694961\n",
      "Iteration 72, loss = 0.53595592\n",
      "Iteration 73, loss = 0.53496416\n",
      "Iteration 74, loss = 0.53397475\n",
      "Iteration 75, loss = 0.53298760\n",
      "Iteration 76, loss = 0.53200338\n",
      "Iteration 77, loss = 0.53103422\n",
      "Iteration 78, loss = 0.53008024\n",
      "Iteration 79, loss = 0.52896857\n",
      "Iteration 80, loss = 0.52722378\n",
      "Iteration 81, loss = 0.52431630\n",
      "Iteration 82, loss = 0.52058110\n",
      "Iteration 83, loss = 0.51943543\n",
      "Iteration 84, loss = 0.51833979\n",
      "Iteration 85, loss = 0.51564040\n",
      "Iteration 86, loss = 0.51181842\n",
      "Iteration 87, loss = 0.50837601\n",
      "Iteration 88, loss = 0.50623207\n",
      "Iteration 89, loss = 0.50356881\n",
      "Iteration 90, loss = 0.49973460\n",
      "Iteration 91, loss = 0.49518270\n",
      "Iteration 92, loss = 0.49104186\n",
      "Iteration 93, loss = 0.48693088\n",
      "Iteration 94, loss = 0.48030616\n",
      "Iteration 95, loss = 0.47082039\n",
      "Iteration 96, loss = 0.45931275\n",
      "Iteration 97, loss = 0.44767120\n",
      "Iteration 98, loss = 0.43789894\n",
      "Iteration 99, loss = 0.43108176\n",
      "Iteration 100, loss = 0.42409413\n",
      "Iteration 101, loss = 0.41528059\n",
      "Iteration 102, loss = 0.40536134\n",
      "Iteration 103, loss = 0.39683626\n",
      "Iteration 104, loss = 0.38865754\n",
      "Iteration 105, loss = 0.37932108\n",
      "Iteration 106, loss = 0.37030809\n",
      "Iteration 107, loss = 0.36259058\n",
      "Iteration 108, loss = 0.35444970\n",
      "Iteration 109, loss = 0.34554606\n",
      "Iteration 110, loss = 0.33718579\n",
      "Iteration 111, loss = 0.32926562\n",
      "Iteration 112, loss = 0.32132930\n",
      "Iteration 113, loss = 0.31312404\n",
      "Iteration 114, loss = 0.30532020\n",
      "Iteration 115, loss = 0.29800113\n",
      "Iteration 116, loss = 0.29058924\n",
      "Iteration 117, loss = 0.28276323\n",
      "Iteration 118, loss = 0.27509386\n",
      "Iteration 119, loss = 0.26845284\n",
      "Iteration 120, loss = 0.26142554\n",
      "Iteration 121, loss = 0.25403212\n",
      "Iteration 122, loss = 0.24812778\n",
      "Iteration 123, loss = 0.24148830\n",
      "Iteration 124, loss = 0.23567272\n",
      "Iteration 125, loss = 0.23056318\n",
      "Iteration 126, loss = 0.22440195\n",
      "Iteration 127, loss = 0.21913564\n",
      "Iteration 128, loss = 0.21468731\n",
      "Iteration 129, loss = 0.20944521\n",
      "Iteration 130, loss = 0.20465046\n",
      "Iteration 131, loss = 0.20030900\n",
      "Iteration 132, loss = 0.19604763\n",
      "Iteration 133, loss = 0.19149713\n",
      "Iteration 134, loss = 0.18723191\n",
      "Iteration 135, loss = 0.18346681\n",
      "Iteration 136, loss = 0.17973950\n",
      "Iteration 137, loss = 0.17594656\n",
      "Iteration 138, loss = 0.17281538\n",
      "Iteration 139, loss = 0.16946780\n",
      "Iteration 140, loss = 0.16619030\n",
      "Iteration 141, loss = 0.16322827\n",
      "Iteration 142, loss = 0.16015832\n",
      "Iteration 143, loss = 0.15732931\n",
      "Iteration 144, loss = 0.15456205\n",
      "Iteration 145, loss = 0.15189028\n",
      "Iteration 146, loss = 0.14931468\n",
      "Iteration 147, loss = 0.14683924\n",
      "Iteration 148, loss = 0.14443942\n",
      "Iteration 149, loss = 0.14216274\n",
      "Iteration 150, loss = 0.13990227\n",
      "Iteration 151, loss = 0.13774548\n",
      "Iteration 152, loss = 0.13565730\n",
      "Iteration 153, loss = 0.13367464\n",
      "Iteration 154, loss = 0.13169824\n",
      "Iteration 155, loss = 0.12977083\n",
      "Iteration 156, loss = 0.12793068\n",
      "Iteration 157, loss = 0.12619155\n",
      "Iteration 158, loss = 0.12446700\n",
      "Iteration 159, loss = 0.12278322\n",
      "Iteration 160, loss = 0.12115315\n",
      "Iteration 161, loss = 0.11953391\n",
      "Iteration 162, loss = 0.11807057\n",
      "Iteration 163, loss = 0.11661477\n",
      "Iteration 164, loss = 0.11514320\n",
      "Iteration 165, loss = 0.11373070\n",
      "Iteration 166, loss = 0.11241213\n",
      "Iteration 167, loss = 0.11109751\n",
      "Iteration 168, loss = 0.10980955\n",
      "Iteration 169, loss = 0.10858838\n",
      "Iteration 170, loss = 0.10736435\n",
      "Iteration 171, loss = 0.10622975\n",
      "Iteration 172, loss = 0.10508513\n",
      "Iteration 173, loss = 0.10398958\n",
      "Iteration 174, loss = 0.10292624\n",
      "Iteration 175, loss = 0.10189652\n",
      "Iteration 176, loss = 0.10084901\n",
      "Iteration 177, loss = 0.09984566\n",
      "Iteration 178, loss = 0.09889458\n",
      "Iteration 179, loss = 0.09795416\n",
      "Iteration 180, loss = 0.09704216\n",
      "Iteration 181, loss = 0.09615332\n",
      "Iteration 182, loss = 0.09529309\n",
      "Iteration 183, loss = 0.09444735\n",
      "Iteration 184, loss = 0.09361703\n",
      "Iteration 185, loss = 0.09280207\n",
      "Iteration 186, loss = 0.09200802\n",
      "Iteration 187, loss = 0.09125393\n",
      "Iteration 188, loss = 0.09051406\n",
      "Iteration 189, loss = 0.08976980\n",
      "Iteration 190, loss = 0.08904790\n",
      "Iteration 191, loss = 0.08835343\n",
      "Iteration 192, loss = 0.08767534\n",
      "Iteration 193, loss = 0.08703059\n",
      "Iteration 194, loss = 0.08638427\n",
      "Iteration 195, loss = 0.08569713\n",
      "Iteration 196, loss = 0.08509061\n",
      "Iteration 197, loss = 0.08449253\n",
      "Iteration 198, loss = 0.08386735\n",
      "Iteration 199, loss = 0.08332060\n",
      "Iteration 200, loss = 0.08272866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(3, 2), learning_rate_init=0.01,\n",
       "              random_state=5, verbose=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfIris2 = MLPClassifier(hidden_layer_sizes=(3,2),\n",
    "                    random_state=5,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.01)\n",
    "clfIris2.fit(X_trainIris2,y_trainIris2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predIris2 = clfIris2.predict(X_testIris2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-setosa</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "Iris-setosa               17                0               0\n",
       "Iris-versicolor            0               10               2\n",
       "Iris-virginica             0                0              16"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastCol2 = dataIris1.shape[1]-1\n",
    "uniqueOutputs2 = dataIris1[lastCol2].unique().tolist()\n",
    "# Creating the confusion matrix\n",
    "cmIris2 = metrics.confusion_matrix(y_testIris2, y_predIris2)\n",
    "# Assigning columns names\n",
    "cm_dfIris2 = pd.DataFrame(cmIris2, \n",
    "            columns = uniqueOutputs2,\n",
    "            index = uniqueOutputs2)\n",
    "# Showing the confusion matrix\n",
    "cm_dfIris2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 17\n",
      "True Negatives: 28\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Sensitivity: 1.0\n",
      "Precision = 1.0\n",
      "Negative Pred Value = 1.0\n",
      "Specificity = 1.0\n",
      "Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "sensitivityiris2,precisioniris2,negativePredValuesiris2,specificityiris2,accuracyiris2 = metric(cmIris2)\n",
    "sensitivityList.append(sensitivityiris2)\n",
    "precisionList.append(precisioniris2)\n",
    "negativePredValuesList.append(negativePredValuesiris2)\n",
    "specificityList.append(specificityiris2)\n",
    "accuracyList.append(accuracyiris2)\n",
    "print(f'Sensitivity: {sensitivityiris2}')\n",
    "print(f'Precision = {precisioniris2}')\n",
    "print(f'Negative Pred Value = {negativePredValuesiris2}')\n",
    "print(f'Specificity = {specificityiris2}')\n",
    "print(f'Accuracy = {accuracyiris2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-', '-', '-', '-', 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisionList = ['-' if str(x)=='nan' else x for x in precisionList]\n",
    "precisionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eksperimen Model MLP\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                         Eksperimen Model MLP                                                        |\n",
      "+---------------------------------------------------+-------------+-----------+----------------------+-----------+--------------------+\n",
      "|                     Eksperimen                    | Sensitivity | Precision | negative Pred Values | Specifity |      Accuracy      |\n",
      "+---------------------------------------------------+-------------+-----------+----------------------+-----------+--------------------+\n",
      "|      Model tanpa pembersihan data - Oil Spill     |     0.0     |     -     |  0.9572953736654805  |    1.0    | 0.9572953736654805 |\n",
      "| Model dengan penghapusan single value - Oil Spill |     0.0     |     -     |  0.9609929078014184  |    1.0    | 0.9609929078014184 |\n",
      "|  Model dengan penghapusan few values - Oil Spill  |     0.0     |     -     |  0.9609929078014184  |    1.0    | 0.9609929078014184 |\n",
      "| Model dengan penghapusan low variance - Oil Spill |     0.0     |     -     |  0.9609929078014184  |    1.0    | 0.9609929078014184 |\n",
      "|        Model tanpa pembersihan data - Iris        |     1.0     |    1.0    |         1.0          |    1.0    |        1.0         |\n",
      "| Model dengan penghapusan data terduplikasi - Iris |     1.0     |    1.0    |         1.0          |    1.0    |        1.0         |\n",
      "+---------------------------------------------------+-------------+-----------+----------------------+-----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "MLPTable = pt()\n",
    "MLPTable.title = 'Eksperimen Model MLP'\n",
    "MLPTable.field_names = [\"Eksperimen\", \"Sensitivity\", \"Precision\", \"negative Pred Values\",'Specifity', 'Accuracy']\n",
    "eksperimen = [\"Model tanpa pembersihan data - Oil Spill\",\"Model dengan penghapusan single value - Oil Spill\",\"Model dengan penghapusan few values - Oil Spill\",\"Model dengan penghapusan low variance - Oil Spill\",\"Model tanpa pembersihan data - Iris\",\"Model dengan penghapusan data terduplikasi - Iris\"]\n",
    "n = len(eksperimen)\n",
    "print('Eksperimen Model MLP')\n",
    "for i in range(n):\n",
    "    MLPTable.add_row([eksperimen[i],sensitivityList[i],precisionList[i],negativePredValuesList[i],specificityList[i],accuracyList[i]])\n",
    "print(MLPTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivityListLR = []\n",
    "precisionListLR = []\n",
    "negativePredValuesListLR = []\n",
    "specificityListLR = []\n",
    "accuracyListLR = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eksperimen Model Logistic Regression\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                   Eksperimen Model logReg                                                                    |\n",
      "+---------------------------------------------------+-------------------+--------------------+----------------------+---------------------+--------------------+\n",
      "|                     Eksperimen                    |    Sensitivity    |     Precision      | negative Pred Values |      Specifity      |      Accuracy      |\n",
      "+---------------------------------------------------+-------------------+--------------------+----------------------+---------------------+--------------------+\n",
      "|      Model tanpa pembersihan data - Oil Spill     | 0.977859778597786 | 0.9636363636363636 | 0.14285714285714285  | 0.09090909090909091 | 0.9432624113475178 |\n",
      "| Model dengan penghapusan single value - Oil Spill | 0.977859778597786 | 0.9636363636363636 | 0.14285714285714285  | 0.09090909090909091 | 0.9432624113475178 |\n",
      "|  Model dengan penghapusan few values - Oil Spill  | 0.988929889298893 | 0.9675090252707581 |         0.4          | 0.18181818181818182 | 0.9574468085106383 |\n",
      "| Model dengan penghapusan low variance - Oil Spill | 0.977859778597786 | 0.9636363636363636 | 0.14285714285714285  | 0.09090909090909091 | 0.9432624113475178 |\n",
      "|        Model tanpa pembersihan data - Iris        |        1.0        |        1.0         |         1.0          |         1.0         |        1.0         |\n",
      "| Model dengan penghapusan data terduplikasi - Iris |        1.0        |        1.0         |         1.0          |         1.0         |        1.0         |\n",
      "+---------------------------------------------------+-------------------+--------------------+----------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "logRegTable = pt()\n",
    "logRegTable.title = 'Eksperimen Model logReg'\n",
    "logRegTable.field_names = [\"Eksperimen\", \"Sensitivity\", \"Precision\", \"negative Pred Values\",'Specifity', 'Accuracy']\n",
    "eksperimen = [\"Model tanpa pembersihan data - Oil Spill\",\"Model dengan penghapusan single value - Oil Spill\",\"Model dengan penghapusan few values - Oil Spill\",\"Model dengan penghapusan low variance - Oil Spill\",\"Model tanpa pembersihan data - Iris\",\"Model dengan penghapusan data terduplikasi - Iris\"]\n",
    "n = len(eksperimen)\n",
    "print('Eksperimen Model Logistic Regression')\n",
    "for i in range(n): \n",
    "    logRegTable.add_row([eksperimen[i],sensitivityListLR[i],precisionListLR[i],negativePredValuesListLR[i],specificityListLR[i],accuracyListLR[i]])\n",
    "print(logRegTable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
